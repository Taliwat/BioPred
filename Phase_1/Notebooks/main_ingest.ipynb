{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **ChEMBL Data Import and Preparation**\n",
        "\n",
        "## Objectives:\n",
        "\n",
        "The first notebook focuses on setting up the data pipeline by:\n",
        "\n",
        "1.  Reading the ChEMBL dataset directly into our Azure MySQL Database from the ChEMBL URL.\n",
        "\n",
        "2.  Taking the new raw data, querying it for what we need at this time, and placing it in a separate database.\n",
        "\n",
        "3.  Examines this new set of data for duplicates and missing values, removing as needed.\n",
        "\n",
        "4.  Saving our work so that we can use this version of the data for the rest of this phase of the project, saving also as a parquet file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Section 1: Import Libraries and Establish Project Root for Directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### First let's set our directory to the root of the project.  Doing so will keep our project on track location-wise and it is a great way to keep yourself out of trouble with your directory issues, by setting your abspath to the root.  We can then in future notebooks refer back to the project_root when needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1739732874581
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root set to: /mnt/batch/tasks/shared/LS_root/mounts/clusters/kalpha18651/code/Users/kalpha1865/BioPred\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define project root\n",
        "project_root = \"/home/azureuser/cloudfiles/code/Users/kalpha1865/BioPred\"\n",
        "\n",
        "# Validate the directory\n",
        "if not os.path.exists(project_root):\n",
        "    raise FileNotFoundError(f\"Project root not found: {project_root}\")\n",
        "\n",
        "# Change working directory to project root if not already\n",
        "if os.getcwd() != project_root:\n",
        "    os.chdir(project_root)\n",
        "\n",
        "print(f\"Project root set to: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Now we can import the rest of our libraries, as well as establish a reference point to our Config file for our database credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1739732879230
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config directory: /home/azureuser/cloudfiles/code/Users/kalpha1865/BioPred/Config\n",
            "Files in Config directory: ['.amlignore', '.amlignore.amltmp', 'config.json', 'config.py', '__pycache__']\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import requests\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "import fastparquet\n",
        "from sqlalchemy import create_engine, text, Index, MetaData, Table, inspect\n",
        "import mysql.connector\n",
        "\n",
        "\n",
        "# Referencing the config file for Azure MySQL Database credentials.\n",
        "config_dir = os.path.join(project_root, \"Config\")\n",
        "sys.path.append(config_dir)\n",
        "print(f\"Config directory: {config_dir}\")\n",
        "print(\"Files in Config directory:\", os.listdir(config_dir))\n",
        "\n",
        "from config import MYSQL_CONFIG\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Section 2: Read and Extract Data from URL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Now we will bring in our ChEMBL data, sending it straight from the site url to our Azure MySQL Database.  We will read in our credentials from a config file for access.  The commands used in the function below can normally be used in the terminal however I wanted to show my work here.  First though we will need to create our databases that we will use in this portion of the project to house and work with the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1739732879471
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Database 'chembl_raw' created successfully.\n",
            "Database 'chembl_phase_1' created successfully.\n",
            "Verification successful: Databases exist in the Azure MySQL server.\n"
          ]
        }
      ],
      "source": [
        "# setting up as a try/except block so we can add error handling.\n",
        "try:\n",
        "    # Set up the connection string to Azure\n",
        "    engine = create_engine(\n",
        "        f\"mysql+mysqlconnector://{MYSQL_CONFIG['username']}:{MYSQL_CONFIG['password']}@\"\n",
        "        f\"{MYSQL_CONFIG['hostname']}:{MYSQL_CONFIG['port']}/\",\n",
        "        connect_args={\n",
        "            \"ssl_ca\" : MYSQL_CONFIG[\"ssl_ca\"],\n",
        "            \"ssl_verify_cert\" : True\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Create the databases needed\n",
        "    with engine.connect() as connection:\n",
        "        connection.execute(text(\"CREATE DATABASE IF NOT EXISTS chembl_raw;\"))\n",
        "        print(\"Database 'chembl_raw' created successfully.\")\n",
        "    \n",
        "        connection.execute(text(\"CREATE DATABASE IF NOT EXISTS chembl_phase_1;\"))\n",
        "        print(\"Database 'chembl_phase_1' created successfully.\")\n",
        "    \n",
        "        # Verify databases exist.\n",
        "        result = connection.execute(text(\"SHOW DATABASES;\"))\n",
        "        databases = [row[0] for row in result]\n",
        "        \n",
        "        if \"chembl_raw\" in databases and \"chembl_phase_1\" in databases:\n",
        "            print(\"Verification successful: Databases exist in the Azure MySQL server.\")\n",
        "        else:\n",
        "            print(\"Error: Databases were not found after creation.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Great the new databases are created and housed in our Azure MySQL server (I verified on the Azure portal as well).  Now let's fetch the url containing our data from ChEMBL and send it to our empty database, so we can query off of it and get what we need for phase_1 data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1739740085113
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing existing directory: /home/azureuser/cloudfiles/code/Users/kalpha1865/BioPred/chembl_35/chembl_35_mysql/\n",
            "Extracting tar file...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/home/azureuser/cloudfiles/code/Users/kalpha1865/BioPred/chembl_35/chembl_35_mysql/': Directory not empty\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during extraction.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tar: chembl_35/chembl_35_mysql/chembl_35_mysql.dmp: Cannot open: No such file or directory\n",
            "tar: Exiting with failure status due to previous errors\n"
          ]
        }
      ],
      "source": [
        "# Function to fetch, extract, and send the contents to our db.\n",
        "\n",
        "def prepare_and_load_data():\n",
        "    tar_file = \"/home/azureuser/cloudfiles/code/Users/kalpha1865/BioPred/chembl_35_mysql.tar.gz\"\n",
        "    extract_dir = \"/home/azureuser/cloudfiles/code/Users/kalpha1865/BioPred/chembl_35/chembl_35_mysql/\"\n",
        "    dmp_file = os.path.join(extract_dir, \"chembl_35_mysql.dmp\")\n",
        "\n",
        "    # Verify tar file\n",
        "    if not os.path.exists(tar_file):\n",
        "        print(f\"{tar_file} not found. Downloading...\")\n",
        "        subprocess.run(\n",
        "            f\"wget ftp://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/latest/chembl_35_mysql.tar.gz -O {tar_file}\",\n",
        "            shell=True\n",
        "        )\n",
        "    \n",
        "    # Clean up existing files\n",
        "    if os.path.exists(extract_dir):\n",
        "        print(f\"Removing existing directory: {extract_dir}\")\n",
        "        subprocess.run(f\"rm -rf {extract_dir}\", shell=True)\n",
        "    \n",
        "    # Extract tar file\n",
        "    print(\"Extracting tar file...\")\n",
        "    process = subprocess.run(f\"tar -xzf {tar_file} -C /home/azureuser/cloudfiles/code/Users/kalpha1865/BioPred/\", shell=True)\n",
        "    if process.returncode != 0:\n",
        "        print(\"Error during extraction.\")\n",
        "        return\n",
        "    \n",
        "    # Verify .dmp file\n",
        "    if not os.path.exists(dmp_file):\n",
        "        print(f\"{dmp_file} not found after extraction.\")\n",
        "        return\n",
        "    \n",
        "    print(\"Loading .dmp file into MySQL...\")\n",
        "    load_command = (\n",
        "        f\"mysql -h biopred.mysql.database.azure.com -u rdm1 -p'tali1327_yo' \"\n",
        "        f\"--ssl-mode=VERIFY_CA --ssl-ca=/home/azureuser/cloudfiles/code/Users/kalpha1865/BioPred/docs/certs/DigiCertGlobalRootCA.crt.pem \"\n",
        "        f\"-D chembl_raw < {dmp_file}\"\n",
        "    )\n",
        "    process = subprocess.run(load_command, shell=True)\n",
        "    if process.returncode == 0:\n",
        "        print(\"Data successfully loaded into MySQL.\")\n",
        "    else:\n",
        "        print(f\"Error loading data. Return code: {process.returncode}\")\n",
        "\n",
        "prepare_and_load_data()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Now that we have the data sent to our database let's create a new connection and check the table names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1739740085339
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tables in raw database: ['action_type', 'activities', 'activity_properties', 'activity_smid', 'activity_stds_lookup', 'activity_supp', 'activity_supp_map', 'assay_class_map', 'assay_classification', 'assay_parameters', 'assay_type', 'assays', 'atc_classification', 'binding_sites', 'bio_component_sequences', 'bioassay_ontology', 'biotherapeutic_components', 'biotherapeutics', 'cell_dictionary', 'chembl_id_lookup', 'chembl_release', 'component_class', 'component_domains', 'component_go', 'component_sequences', 'component_synonyms', 'compound_properties', 'compound_records', 'compound_structural_alerts', 'compound_structures', 'confidence_score_lookup', 'curation_lookup', 'data_validity_lookup', 'defined_daily_dose', 'docs', 'domains', 'drug_indication', 'drug_mechanism', 'drug_warning', 'formulations', 'frac_classification', 'go_classification', 'hrac_classification', 'indication_refs', 'irac_classification', 'ligand_eff', 'mechanism_refs', 'metabolism', 'metabolism_refs', 'molecule_atc_classification', 'molecule_dictionary', 'molecule_frac_classification', 'molecule_hierarchy', 'molecule_hrac_classification', 'molecule_irac_classification', 'molecule_synonyms', 'organism_class', 'patent_use_codes', 'predicted_binding_domains', 'product_patents', 'products', 'protein_class_synonyms', 'protein_classification', 'relationship_type', 'research_companies', 'research_stem', 'site_components', 'source', 'structural_alert_sets', 'structural_alerts', 'target_components', 'target_dictionary', 'target_relations', 'target_type', 'tissue_dictionary', 'usan_stems', 'variant_sequences', 'version', 'warning_refs']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define a new engine for the connection, specifying our new database for the raw data.\n",
        "raw_engine = create_engine(\n",
        "        f\"mysql+mysqlconnector://{MYSQL_CONFIG['username']}:{MYSQL_CONFIG['password']}@\"\n",
        "        f\"{MYSQL_CONFIG['hostname']}:{MYSQL_CONFIG['port']}/{MYSQL_CONFIG['database_raw']}\",\n",
        "        connect_args={\n",
        "            \"ssl_ca\" : MYSQL_CONFIG[\"ssl_ca\"],\n",
        "            \"ssl_verify_cert\" : True\n",
        "        }\n",
        "    )\n",
        "\n",
        "with raw_engine.connect() as connection:\n",
        "    result = connection.execute(text(\"SHOW TABLES;\"))\n",
        "    print(\"Tables in raw database:\", [row[0] for row in result.fetchall()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Section 3: Querying Our New Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Let's take a look at the schema to get a visual for the ChEMBL data. Seen below.  We will use this to formulate our query and our indexes for the next part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/latest/chembl_35_schema.png\" alt = \"ChEMBL Schema\" width = 2000>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Next we will set a few indexes for our data; this will help considerably when we go to query our data.  We will also set indexes with a general theme, setting indexes for features we will need and use throughout this project so we don't change them again as this is the raw data we will be iterating on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Before creating our indexes though we need to map the MetaData of our tables that we will need for our joins in our query.  This will allow us to query a lot faster through our forthcoming indexes, as with those we won't need to scan the whole dataset every time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1739740085727
        }
      },
      "outputs": [
        {
          "ename": "InternalError",
          "evalue": "(mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction\n[SQL: SHOW CREATE TABLE `assays`]\n(Background on this error at: https://sqlalche.me/e/20/2j85)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/engine/default.py:941\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 941\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/mysql/connector/cursor.py:537\u001b[0m, in \u001b[0;36mMySQLCursor.execute\u001b[0;34m(self, operation, params, multi)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_result(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcmd_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/mysql/connector/opentelemetry/context_propagation.py:106\u001b[0m, in \u001b[0;36mwith_context_propagation.<locals>.wrapper\u001b[0;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/mysql/connector/connection.py:872\u001b[0m, in \u001b[0;36mMySQLConnection.cmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 872\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_cmd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mServerCmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQUERY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProgrammingError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/mysql/connector/connection.py:648\u001b[0m, in \u001b[0;36mMySQLConnection._handle_result\u001b[0;34m(self, packet)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m packet[\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m255\u001b[39m:\n\u001b[0;32m--> 648\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_exception(packet)\n\u001b[1;32m    650\u001b[0m \u001b[38;5;66;03m# We have a text result set\u001b[39;00m\n",
            "\u001b[0;31mInternalError\u001b[0m: 1213 (40001): Deadlock found when trying to get lock; try restarting transaction",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m metadata \u001b[38;5;241m=\u001b[39m MetaData()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreflect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_engine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Reflect the tables to the metadata.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m compound_structures \u001b[38;5;241m=\u001b[39m Table(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompound_structures\u001b[39m\u001b[38;5;124m\"\u001b[39m, metadata, autoload_with\u001b[38;5;241m=\u001b[39mraw_engine)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/sql/schema.py:5828\u001b[0m, in \u001b[0;36mMetaData.reflect\u001b[0;34m(self, bind, schema, views, only, extend_existing, autoload_replace, resolve_fks, **dialect_kwargs)\u001b[0m\n\u001b[1;32m   5821\u001b[0m     load \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   5822\u001b[0m         name\n\u001b[1;32m   5823\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m only\n\u001b[1;32m   5824\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m extend_existing \u001b[38;5;129;01mor\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m current\n\u001b[1;32m   5825\u001b[0m     ]\n\u001b[1;32m   5826\u001b[0m \u001b[38;5;66;03m# pass the available tables so the inspector can\u001b[39;00m\n\u001b[1;32m   5827\u001b[0m \u001b[38;5;66;03m# choose to ignore the filter_names\u001b[39;00m\n\u001b[0;32m-> 5828\u001b[0m _reflect_info \u001b[38;5;241m=\u001b[39m \u001b[43minsp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_reflection_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mavailable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mavailable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreloaded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine_reflection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mObjectScope\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mANY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdialect_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5836\u001b[0m reflect_opts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_reflect_info\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _reflect_info\n\u001b[1;32m   5838\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m load:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/engine/reflection.py:2015\u001b[0m, in \u001b[0;36mInspector._get_reflection_info\u001b[0;34m(self, schema, filter_names, available, _reflect_info, **kw)\u001b[0m\n\u001b[1;32m   2011\u001b[0m         res \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2012\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m   2014\u001b[0m info \u001b[38;5;241m=\u001b[39m _ReflectionInfo(\n\u001b[0;32m-> 2015\u001b[0m     columns\u001b[38;5;241m=\u001b[39m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2016\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_multi_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_filter_names_from_meth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m   2017\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   2018\u001b[0m     pk_constraint\u001b[38;5;241m=\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_multi_pk_constraint),\n\u001b[1;32m   2019\u001b[0m     foreign_keys\u001b[38;5;241m=\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_multi_foreign_keys),\n\u001b[1;32m   2020\u001b[0m     indexes\u001b[38;5;241m=\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_multi_indexes),\n\u001b[1;32m   2021\u001b[0m     unique_constraints\u001b[38;5;241m=\u001b[39mrun(\n\u001b[1;32m   2022\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_multi_unique_constraints, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m     ),\n\u001b[1;32m   2024\u001b[0m     table_comment\u001b[38;5;241m=\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_multi_table_comment, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m   2025\u001b[0m     check_constraints\u001b[38;5;241m=\u001b[39mrun(\n\u001b[1;32m   2026\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_multi_check_constraints, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2027\u001b[0m     ),\n\u001b[1;32m   2028\u001b[0m     table_options\u001b[38;5;241m=\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_multi_table_options, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m   2029\u001b[0m     unreflectable\u001b[38;5;241m=\u001b[39munreflectable,\n\u001b[1;32m   2030\u001b[0m )\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _reflect_info:\n\u001b[1;32m   2032\u001b[0m     _reflect_info\u001b[38;5;241m.\u001b[39mupdate(info)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/engine/reflection.py:2001\u001b[0m, in \u001b[0;36mInspector._get_reflection_info.<locals>.run\u001b[0;34m(meth, optional, check_filter_names_from_meth)\u001b[0m\n\u001b[1;32m   1999\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2000\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_result:\n\u001b[0;32m-> 2001\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilter_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2002\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m check_filter_names_from_meth \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m res:\n\u001b[1;32m   2003\u001b[0m             \u001b[38;5;66;03m# method returned no result data.\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m             \u001b[38;5;66;03m# skip any future call methods\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m             has_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/engine/reflection.py:930\u001b[0m, in \u001b[0;36mInspector.get_multi_columns\u001b[0;34m(self, schema, filter_names, kind, scope, **kw)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return information about columns in all objects in the given\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;124;03mschema.\u001b[39;00m\n\u001b[1;32m    895\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;124;03m.. seealso:: :meth:`Inspector.get_columns`\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation_context() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[0;32m--> 930\u001b[0m     table_col_defs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_multi_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilter_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m            \u001b[49m\u001b[43mscope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfo_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instantiate_types(table_col_defs\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table_col_defs\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/engine/default.py:1118\u001b[0m, in \u001b[0;36mDefaultDialect._default_multi_reflect\u001b[0;34m(self, single_tbl_method, connection, kind, schema, filter_names, scope, **kw)\u001b[0m\n\u001b[1;32m   1114\u001b[0m key \u001b[38;5;241m=\u001b[39m (schema, table)\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (\n\u001b[1;32m   1117\u001b[0m         key,\n\u001b[0;32m-> 1118\u001b[0m         \u001b[43msingle_tbl_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1121\u001b[0m     )\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mUnreflectableTableError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m unreflectable:\n",
            "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mget_columns\u001b[0;34m(self, connection, table_name, schema, **kw)\u001b[0m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/engine/reflection.py:106\u001b[0m, in \u001b[0;36mcache\u001b[0;34m(fn, self, con, *args, **kw)\u001b[0m\n\u001b[1;32m    104\u001b[0m ret: _R \u001b[38;5;241m=\u001b[39m info_cache\u001b[38;5;241m.\u001b[39mget(key)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     info_cache[key] \u001b[38;5;241m=\u001b[39m ret\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/dialects/mysql/base.py:2984\u001b[0m, in \u001b[0;36mMySQLDialect.get_columns\u001b[0;34m(self, connection, table_name, schema, **kw)\u001b[0m\n\u001b[1;32m   2982\u001b[0m \u001b[38;5;129m@reflection\u001b[39m\u001b[38;5;241m.\u001b[39mcache\n\u001b[1;32m   2983\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_columns\u001b[39m(\u001b[38;5;28mself\u001b[39m, connection, table_name, schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m-> 2984\u001b[0m     parsed_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parsed_state_or_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\n\u001b[1;32m   2986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parsed_state\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m   2988\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m parsed_state\u001b[38;5;241m.\u001b[39mcolumns\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/dialects/mysql/base.py:3262\u001b[0m, in \u001b[0;36mMySQLDialect._parsed_state_or_create\u001b[0;34m(self, connection, table_name, schema, **kw)\u001b[0m\n\u001b[1;32m   3259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parsed_state_or_create\u001b[39m(\n\u001b[1;32m   3260\u001b[0m     \u001b[38;5;28mself\u001b[39m, connection, table_name, schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw\n\u001b[1;32m   3261\u001b[0m ):\n\u001b[0;32m-> 3262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_parser\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3266\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfo_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minfo_cache\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3267\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36m_setup_parser\u001b[0;34m(self, connection, table_name, schema, **kw)\u001b[0m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/engine/reflection.py:106\u001b[0m, in \u001b[0;36mcache\u001b[0;34m(fn, self, con, *args, **kw)\u001b[0m\n\u001b[1;32m    104\u001b[0m ret: _R \u001b[38;5;241m=\u001b[39m info_cache\u001b[38;5;241m.\u001b[39mget(key)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     info_cache[key] \u001b[38;5;241m=\u001b[39m ret\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/dialects/mysql/base.py:3289\u001b[0m, in \u001b[0;36mMySQLDialect._setup_parser\u001b[0;34m(self, connection, table_name, schema, **kw)\u001b[0m\n\u001b[1;32m   3283\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tabledef_parser\n\u001b[1;32m   3284\u001b[0m full_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   3285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midentifier_preparer\u001b[38;5;241m.\u001b[39m_quote_free_identifiers(\n\u001b[1;32m   3286\u001b[0m         schema, table_name\n\u001b[1;32m   3287\u001b[0m     )\n\u001b[1;32m   3288\u001b[0m )\n\u001b[0;32m-> 3289\u001b[0m sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_create_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcharset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_name\u001b[49m\n\u001b[1;32m   3291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parser\u001b[38;5;241m.\u001b[39m_check_view(sql):\n\u001b[1;32m   3293\u001b[0m     \u001b[38;5;66;03m# Adapt views to something table-like.\u001b[39;00m\n\u001b[1;32m   3294\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_describe_table(\n\u001b[1;32m   3295\u001b[0m         connection, \u001b[38;5;28;01mNone\u001b[39;00m, charset, full_name\u001b[38;5;241m=\u001b[39mfull_name\n\u001b[1;32m   3296\u001b[0m     )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/dialects/mysql/base.py:3397\u001b[0m, in \u001b[0;36mMySQLDialect._show_create_table\u001b[0;34m(self, connection, table, charset, full_name)\u001b[0m\n\u001b[1;32m   3393\u001b[0m rp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3394\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   3395\u001b[0m     rp \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_user_error_events\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m-> 3397\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_driver_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3398\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mDBAPIError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_error_code(e\u001b[38;5;241m.\u001b[39morig) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1146\u001b[39m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1779\u001b[0m, in \u001b[0;36mConnection.exec_driver_sql\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1774\u001b[0m execution_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execution_options\u001b[38;5;241m.\u001b[39mmerge_with(\n\u001b[1;32m   1775\u001b[0m     execution_options\n\u001b[1;32m   1776\u001b[0m )\n\u001b[1;32m   1778\u001b[0m dialect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\n\u001b[0;32m-> 1779\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_statement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1846\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1986\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1983\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1986\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1987\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2355\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2353\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2354\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2357\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1965\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1972\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1973\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1974\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1978\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1979\u001b[0m     )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sqlalchemy/engine/default.py:941\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 941\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/mysql/connector/cursor.py:537\u001b[0m, in \u001b[0;36mMySQLCursor.execute\u001b[0;34m(self, operation, params, multi)\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_iter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mcmd_query_iter(stmt))\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_result(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcmd_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhave_next_result:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/mysql/connector/opentelemetry/context_propagation.py:106\u001b[0m, in \u001b[0;36mwith_context_propagation.<locals>.wrapper\u001b[0;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     cnx\u001b[38;5;241m.\u001b[39mquery_attrs_append(value\u001b[38;5;241m=\u001b[39m(TRACEPARENT_HEADER_NAME, tp_header))\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tp_header \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/mysql/connector/connection.py:872\u001b[0m, in \u001b[0;36mMySQLConnection.cmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    870\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(packet)\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 872\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_cmd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mServerCmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQUERY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProgrammingError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3948\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading local data is disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m err\u001b[38;5;241m.\u001b[39mmsg:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/mysql/connector/connection.py:648\u001b[0m, in \u001b[0;36mMySQLConnection._handle_result\u001b[0;34m(self, packet)\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_eof(packet)\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m packet[\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m255\u001b[39m:\n\u001b[0;32m--> 648\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_exception(packet)\n\u001b[1;32m    650\u001b[0m \u001b[38;5;66;03m# We have a text result set\u001b[39;00m\n\u001b[1;32m    651\u001b[0m column_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mparse_column_count(packet)\n",
            "\u001b[0;31mInternalError\u001b[0m: (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction\n[SQL: SHOW CREATE TABLE `assays`]\n(Background on this error at: https://sqlalche.me/e/20/2j85)"
          ]
        }
      ],
      "source": [
        "metadata = MetaData()\n",
        "\n",
        "metadata.reflect(bind=raw_engine)\n",
        "\n",
        "# Reflect the tables to the metadata.\n",
        "compound_structures = Table(\"compound_structures\", metadata, autoload_with=raw_engine)\n",
        "activities = Table(\"activities\", metadata, autoload_with=raw_engine)\n",
        "assays = Table(\"assays\", metadata, autoload_with=raw_engine)\n",
        "target_dictionary = Table(\"target_dictionary\", metadata, autoload_with=raw_engine)\n",
        "compound_properties = Table(\"compound_properties\", metadata, autoload_with=raw_engine)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### And a check to see existing indexes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1739740086506
        }
      },
      "outputs": [],
      "source": [
        "inspector = inspect(raw_engine)\n",
        "indexes = inspector.get_indexes(\"compound_structures\") # Example table\n",
        "print(indexes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Now let's create a function to add our new indexes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1739740629924
        }
      },
      "outputs": [],
      "source": [
        "# Instantiate function to create new index if it doesn't exist\n",
        "def create_index(table_name, index_name, column_name):\n",
        "    inspector = inspect(raw_engine)\n",
        "    existing_indexes = [idx[\"name\"] for idx in inspector.get_indexes(table_name)]\n",
        "    if index_name not in existing_indexes:\n",
        "        Index(index_name, column_name).create(raw_engine)\n",
        "        print(f\"Index {index_name} created successfully.\")\n",
        "    else:\n",
        "        print(f\"Index {index_name} already exists. Skipping creation.\")\n",
        "\n",
        "# Use function to add new wanted indexes\n",
        "\n",
        "# First the indexes for the joins\n",
        "create_index(\"compound_structures\", \"ix_molregno\", compound_structures.c.molregno)\n",
        "create_index(\"activities\", \"ix_activities_molregno\", activities.c.molregno)\n",
        "create_index(\"assays\", \"ix_assay_id\", assays.c.assay_id)\n",
        "create_index(\"target_dictionary\", \"ix_tid\", target_dictionary.c.tid)\n",
        "\n",
        "# Now the indexes for filtering\n",
        "create_index(\"compound_properties\", \"ix_full_mwt\", compound_properties.c.full_mwt)\n",
        "create_index(\"compound_properties\", \"ix_hba_lipinski\", compound_properties.c.hba_lipinski)\n",
        "create_index(\"compound_properties\", \"ix_hbd_lipinski\", compound_properties.c.hbd_lipinski)\n",
        "create_index(\"compound_properties\", \"ix_alogp\", compound_properties.c.alogp)\n",
        "create_index(\"compound_properties\", \"ix_psa\", compound_properties.c.psa)\n",
        "create_index(\"compound_properties\", \"ix_rtb\", compound_properties.c.rtb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### We will first attempt to run the whole query as it is first, then slowly editing and changing as we see results based on duplicate and missing value numbers.  The query below is our final product after numerous iterations, as we relaxed our parameters from Lipinski's Rule of Five set to allow for an increase in data allotment and made sure that our pref_name feature was intact without pulling in a lot of missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1739744942910
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# Query the raw data to get what we need in our phase_1_db.\n",
        "def query_phase_1_data():\n",
        "    # Targeted query for phase 1 data with subqueries for better processing\n",
        "    query = text(f\"\"\"           \n",
        "    WITH phase_1_cte AS(\n",
        "        SELECT DISTINCT cs.canonical_smiles, cs.molregno,\n",
        "            MIN(cp.full_mwt) AS full_mwt, MIN(cp.alogp) AS alogp,\n",
        "            MIN(cp.psa) AS psa, MIN(cp.hba_lipinski) AS hba_lipinski, MIN(cp.hbd_lipinski) AS hbd_lipinski,\n",
        "            MIN(cp.aromatic_rings) AS aromatic_rings, MIN(cp.heavy_atoms) AS heavy_atoms,\n",
        "            MIN(cp.rtb) AS rtb, cp.molecular_species, fa.min_standard_value,\n",
        "            td.pref_name, td.tid, td.target_type\n",
        "        FROM compound_structures cs\n",
        "        LEFT JOIN compound_properties cp ON cs.molregno = cp.molregno\n",
        "        LEFT JOIN (\n",
        "            SELECT molregno, MIN(standard_value) AS min_standard_value, assay_id\n",
        "            FROM activities\n",
        "            WHERE standard_value BETWEEN 0 AND 500\n",
        "                AND standard_type IN ('IC50', 'EC50')\n",
        "            GROUP BY molregno, assay_id\n",
        "        ) fa ON cs.molregno = fa.molregno\n",
        "        LEFT JOIN assays ass ON fa.assay_id = ass.assay_id\n",
        "        LEFT JOIN target_dictionary td ON ass.tid = td.tid\n",
        "        WHERE\n",
        "            cp.full_mwt BETWEEN 100 AND 600\n",
        "            AND cp.alogp BETWEEN -1 AND 6\n",
        "            AND cp.psa <= 180\n",
        "            AND cp.rtb <= 15\n",
        "            AND cp.hbd_lipinski <= 7\n",
        "            AND cp.hba_lipinski <= 15\n",
        "            AND td.pref_name IS NOT NULL\n",
        "        GROUP BY\n",
        "            cs.canonical_smiles,\n",
        "            cp.molecular_species,\n",
        "            td.pref_name,\n",
        "            td.tid,\n",
        "            td.target_type,\n",
        "            fa.min_standard_value\n",
        "        )\n",
        "        SELECT\n",
        "            canonical_smiles,\n",
        "            molregno,\n",
        "            full_mwt,\n",
        "            alogp,\n",
        "            psa,\n",
        "            hba_lipinski,\n",
        "            hbd_lipinski,\n",
        "            aromatic_rings,\n",
        "            heavy_atoms,\n",
        "            rtb,\n",
        "            molecular_species,\n",
        "            min_standard_value,\n",
        "            pref_name,\n",
        "            tid,\n",
        "            target_type,\n",
        "            RANK() OVER (ORDER BY min_standard_value ASC) AS rank_min_standard_value,\n",
        "            RANK() OVER(PARTITION BY molregno ORDER BY min_standard_value ASC) AS rank_molregno_min_standard_value,\n",
        "            RANK() OVER(PARTITION BY tid ORDER BY min_standard_value ASC) AS rank_tid_min_std_value\n",
        "        FROM phase_1_cte;\n",
        "        \"\"\")\n",
        "\n",
        "\n",
        "    # Execute query with error handling\n",
        "    try:\n",
        "        # Execute query and fetch results\n",
        "        with raw_engine.connect() as connection:\n",
        "            result = connection.execute(query) \n",
        "            df_phase_1 = pd.DataFrame(result.fetchall(), columns = result.keys())\n",
        "            print(f\"Query returned dataset shape: {df_phase_1.shape}\")\n",
        "            \n",
        "            # Drop the molregno feature as we no longer need.\n",
        "            df_phase_1.drop(columns = ['molregno'], inplace = True)\n",
        "            \n",
        "            return df_phase_1\n",
        "\n",
        "    except Exception as e:\n",
        "            print(f\"Error querying phase 1 data: {e}\")\n",
        "            return pd.DataFrame()\n",
        "    \n",
        "\n",
        "# Check the data for duplicates and missing values before saving.\n",
        "def check_data_quality(df):\n",
        "    if df.empty:\n",
        "        print(\"DataFrame is empty.  Skipping quality checks.\")\n",
        "        return\n",
        "    \n",
        "    print(\"Checking for duplicates...\")\n",
        "    print(f\"Number of duplicate canonical_smiles: {df['canonical_smiles'].duplicated().sum()}\")\n",
        "    \n",
        "    print(\"\\nChecking for missing values...\")\n",
        "    print(df.isna().sum())\n",
        "\n",
        "# Now run both functions\n",
        "df_phase_1 = query_phase_1_data()\n",
        "check_data_quality(df_phase_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Now we can remove the duplicates and the small amount of rows in molecular_species.  We don't want any duplicated data in canonical_smiles as that is going to be our target feature, and the amount of missing values in molecular_species is negligible (0.4%) so there isn't much reason to look into that at this time and removing them to have a clean df is optimal at this time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1739748082622
        }
      },
      "outputs": [],
      "source": [
        "df_phase_1 = df_phase_1.drop_duplicates(subset = \"canonical_smiles\")\n",
        "df_phase_1 = df_phase_1.dropna(subset = ['molecular_species'])\n",
        "print(df_phase_1.shape)\n",
        "print(df_phase_1.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Just around ~343k rows after the query and clean.  I am okay with this as I am opting for quality data for this phase of the project and it will help our modeling.  We also will have a lot of feature engineering and feature formatting and manipulation to do so this data will be expanding.  Let's save it and finish up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### First we need to make another connection engine for phase_1_data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1739748101872
        }
      },
      "outputs": [],
      "source": [
        "# Define a new engine for the connection, specifying our new database for the phase_! data.\n",
        "phase_1_engine = create_engine(\n",
        "        f\"mysql+mysqlconnector://{MYSQL_CONFIG['username']}:{MYSQL_CONFIG['password']}@\"\n",
        "        f\"{MYSQL_CONFIG['hostname']}:{MYSQL_CONFIG['port']}/{MYSQL_CONFIG['database_phase_1']}\",\n",
        "        connect_args={\n",
        "            \"ssl_ca\" : MYSQL_CONFIG[\"ssl_ca\"],\n",
        "            \"ssl_verify_cert\" : True\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"Phase 1 database engine created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1739748144944
        }
      },
      "outputs": [],
      "source": [
        "# Try/except block here to save to the MySQL database\n",
        "try:\n",
        "    df_phase_1.to_sql(\n",
        "        name=\"df_phase_1_data\",\n",
        "            con=phase_1_engine,\n",
        "        if_exists=\"replace\",\n",
        "        index = False,\n",
        "        chunksize= 10000        \n",
        "    )\n",
        "    print(f\"Results successfully saved to phase_1_data\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving to target database: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### We will also save as a parquet file so we can carry over and use in our EDA notebook next."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1739748153546
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "file_path = \"/home/azureuser/cloudfiles/code/Users/kalpha1865/BioPred/Data/df_files/df_phase_1.parquet\"\n",
        "df_phase_1.to_parquet(file_path, index = False)\n",
        "print(\"Queried phase 1 data saved as Parquet in df_files in Data folder.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### As a final step we will dispose of our connections to our engine(s)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1739748161708
        }
      },
      "outputs": [],
      "source": [
        "raw_engine.dispose()\n",
        "phase_1_engine.dispose()\n",
        "\n",
        "print(\"All database connections have been closed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
